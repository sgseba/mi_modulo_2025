# -*- coding: utf-8 -*-
"""Mis_Clases_Limpias.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYZ6IMuqosf5AAsDFcdl9p3ZpcZmQC8R
"""

# 11-06-25: modificaciones menores: low, high, loc, scale.
class GeneradoraDeDatos:
  # Recibe n entero = cantidad de datos a generar.
  def __init__(self, n):
    self.n = n

  def genera_datos_dist_uniforme(self, inf=0, sup=1):
    # Usa n, devuelve array de datos con distrib uniforme.
    return np.random.uniform(low=inf, high=sup, size=self.n)

  def genera_datos_dist_norm(self, media=0, desvio=1):
    # Usa n. Puede recibir media, desvío. Devuelve array de datos con distrib N(media,desvio).
    return np.random.normal(self.n,loc=media,scale=desvio)

  def genera_datos_BS(self):
    # Usa n, devuelve array de datos_BS ~ N(0,1), Bart Simpson
    y = 0.5 + np.random.normal(self.n,0,1)
    for j in range(5):
      y += 0.1 * np.random.normal( self.n, 0.5*j - 1, 0.1)
    return y

  def densidad_normal(self, x, media=0, desvio=1):
    # Recibe x, array de grilla. Puede recibir media, desvío.
    # Devuelve la densidad de probabilidad N(0,1).
    return norm.pdf(x,loc=media,scale=desvio)

# 11-06-25: eliminé sum en kernel_gauss y kernel_unif (estaba en mi_densidad), y agregué _ a algunos métodos.
class Estimacion:
  def __init__(self, datos):
      self.datos = datos

  def genera_histograma(self, h):
    # Genera histograma.
    # Necesita datos y h (ventana).
    # Retorna puntos separadores de bins y recuento de cada bin.

    bins = np.arange(min(self.datos), max(self.datos)+h,h)
    histo = np.zeros(len(bins)-1)
    for dato in self.datos:
      for i in range(len(histo)):
        if bins[i] <= dato < bins[i+1]:
          histo[i] +=1
          break
    histo /= (len(self.datos) * h)
    return bins, histo

  def evalua_histograma(self, h, x):
      # Utiliza genera_histograma, a partir de datos y h,  como función de densidad para estimar las probabilidades en x.

      bins, frec = self.genera_histograma(h)
      estim_hist = np.zeros(len(x))
      for j in range(len(x)):
        for i in range(len(bins)-1):
            if bins[i] <= x[j] < bins[i+1]:
              estim_hist[j] = frec[i]
              break
      return estim_hist


  def _caracteristica (self,x,int_inf, int_sup):
    # Recibe x.
    # Devuelve 1 si x en (,), 0 si no.
    return 1*((x>int_inf) & (x<int_sup))

  def _kernel_gaussiano(self,x):
    # Kernel gaussiano estándar
    # Recibe x, devuelve K(x)
    valor_kernel_gaussiano = (1/np.sqrt(2*np.pi)) * np.exp(-x**2/2)
    return valor_kernel_gaussiano

  def _kernel_uniforme(self,x):
    # Kernel uniforme estándar
    # Recibe x, devuelve K(x)
    valor_kernel_uniforme = 0.5*self._caracteristica(x,-1,1)
    return valor_kernel_uniforme

  def _kernel_cuadra(self,x):
    # Kernel cuadrático estándar
    # Recibe x, devuelve K(x)
    return 0.75*(1-x**2) * self._caracteristica(x, -1, 1)

  def _kernel_triangu(self,x):
    # Kernel triangular estándar
    # Recibe x, devuelve K(x)
    return (1+x)*self._caracteristica(x,-1,0) + (1-x)*self._caracteristica(x,0,1)

  def mi_densidad(self, x, h, kernel):
    # Recibe x: Puntos en los que se evaluará la densidad.
    # Recibe h: Ancho de la ventana (bandwidth).
    # Recibe kernel: string del kernel a usar.
    # Usa: self.datos: Datos

    n = len(x)
    density = np.zeros_like(x)
    for i in range(n):

        if kernel in ['uniforme', 'Uniforme', 'KUnif']:
          density[i] = np.sum(self._kernel_uniforme((self.datos - x[i])/h))

        elif kernel in ['gauss', 'Gauss', 'gaussiano', 'Gaussiano', 'KGauss']:
          density[i] = np.sum(self._kernel_gaussiano((self.datos - x[i])/h))

        elif kernel in ['cuadra', 'Cuadra', 'KCuadra', 'Cuadra','Cuadrado', 'KCuadrado']:
          density[i] = np.sum(self._kernel_cuadra((self.datos - x[i])/h))

        elif kernel in ['triangu', 'Triangu', 'KTriangu', 'triangular', 'Triangular', 'KTriangular']:
          density[i] = np.sum(self._kernel_triangu((self.datos - x[i])/h))

    return density / (len(self.datos)*h)

  def miqqplot(self):

    cuantiles = np.arange(1,11)/11
    cuantiles_teoricos = norm.ppf(cuantiles)

    data_ord = np.zeros_like(cuantiles)
    for i in range(len(cuantiles)):
      data_ord[i] = np.sort(self.datos)[int(cuantiles[i]*len(self.datos)) - 1]
    cuantiles_muestrales = (data_ord - np.mean(self.datos))/np.std(self.datos)

    plt.scatter(cuantiles_teoricos, cuantiles_muestrales, color='blue', marker='o')
    plt.xlabel('Cuantiles teóricos')
    plt.ylabel('Cuantiles muestrales')
    plt.plot(cuantiles_teoricos,cuantiles_teoricos , linestyle='-', color='red')
    plt.show()

  def qqpplot_teorico(self):
    sm.qqplot((self.datos-np.mean(self.datos))/np.std(self.datos), line='45')
    plt.title('QQ Plot')
    plt.show()

# 11-06-25: correcciones menores: asarray, saco return self.resumen, cambié self.calcular_regresion() en grafico_scatter por el if,
# VERSION REDUCIDA 27-04-25: manual y con statsmodels
import numpy as np
from scipy.stats import norm
from scipy.stats import t
import matplotlib.pyplot as plt
import statsmodels.api as sm

class RegresionLinealSimple():

    # Recibe los datos como 2 ARRAY SIN ENCABEZADO y los convierte en array de numpy
    # x variable predictora=keys(), y variable respuesta=values().
    # Método grafico_scatter_y_lineal: genera la recta con b0 y b1, y grafica datos y recta.
    # Método estimar_y: genera los datos estimados a partir de x.
    # Método calcular_residuos: y_estim - y_dato
    # Método calcular_varianza_residuos: da eso.
    # Método t_obs: calcula el t_obs para b1.
    # Método calcula_region_rechazo: dado alfa, calcula el t_critico para la región de rechazo de H0: b1=0.

  def __init__(self,datos_y, datos_x, label_y='y', label_x='x'):
      self.datos_x = np.asarray(datos_x, dtype=float)
      self.datos_y = np.asarray(datos_y, dtype=float)
      self.datos_x_label = label_x
      self.datos_y_label = label_y
      self.resumen = {}

  def calcular_regresion(self):
      # Calcula los atributos esenciales del modelo de regresión lineal simple.
        #- Parámetros b0,b1
        #- y_estimada por la regresión
        #- residuos: datos originales - estimados
        #- varianza_residuos
        #- varianza_b1
        #- varianza_b0
        #- t_critico_05: valor de la distribución teórica t, con (n-2) gl, alfa=0.05
        #- t_obs_b1: valor de la distribución t para el valor observado de b1.
        #- p_valor_b1: p-valor para el valor t_obs_b1, bilateral, alfa=0.05 (0.025-0.975)
      # Métodos:
        #- Calcular graficar dispersión de datos originales y recta de ajuste
        #- Calcular t_obs_b1_otro para testear H0: b1=otro_valor, H1: !=otro_valor  (por DEFECTO=0)
        #- Calcular t_obs_b0_otro para testear H0: b0=otro_valor, H1: !=otro_valor  (por DEFECTO=0)
        #- Calcular t_critico bilateral para otro alfa (por DEFECTO=0.05)
        #- Calcular intervalo de confianza para la media de y, dado x0.
        #- Calcular intervalo de predicción puntual para y, dado x0.

      ## ATRIBUTOS
      # Estimadores de los parámetros: b0_est y b1_est
      self.b1_est = np.sum((self.datos_x - np.mean(self.datos_x)) * (self.datos_y - np.mean(self.datos_y))) / np.sum((self.datos_x -  np.mean(self.datos_x))**2)       #m_11 / m_20
      self.b0_est = np.mean(self.datos_y) - self.b1_est * np.mean(self.datos_x)

      # Predichos y_estimada
      self.y_estimada = self.b0_est + self.b1_est * self.datos_x

      # Residuos: y-y_estimada
      self.residuos = self.datos_y - self.y_estimada

      # Estimador de varianza de residuos sigma^2
      self.sigma2_est = np.sum(self.residuos**2)/(len(self.datos_x)-2)

      # Estimador de varianza b1_estimador
      self.varianza_b1_est = self.sigma2_est / np.sum((self.datos_x - np.mean(self.datos_x))**2)

      # Estimador de varianza b0_estimador
      self.varianza_b0_est = self.sigma2_est * np.sum(self.datos_x**2)/ (len(self.datos_x) * np.sum((self.datos_x - np.mean(self.datos_x))**2))

      # Calcula t_critico_05 para datos_x, alfa =0.05.
      alfa = 0.05
      self.t_critico_05 = t.ppf(1-(alfa/2),len(self.datos_x)-2)

      # Calcula t_obs_b1 para H0: b1=0, H1: !=0.
      self.t_obs_b1 = self.b1_est/np.sqrt(self.varianza_b1_est)

      # Calcula t_obs_b0 para H0: b0=0, H1: !=0.
      self.t_obs_b0 = self.b0_est/np.sqrt(self.varianza_b0_est)

      # Calcula el p_valor para H0: b1 = 0, H1: != 0.
      self.p_valor_b1= 2*(1-t.cdf(np.abs(self.t_obs_b1),len(self.datos_x)-2))

      # Creo resumen diccionario
      self.resumen = {'b0_est': self.b0_est,
                      'b1_est': self.b1_est,
                      'y_est': self.y_estimada,
                      'residuos': self.residuos,
                      'varianza_residuos_est': self.sigma2_est,
                      'varianza_b0_est': self.varianza_b0_est,
                      'desvio_b0_est': np.sqrt(self.varianza_b0_est),
                      'varianza_b_est': self.varianza_b1_est,
                      'desvio_b1_est': np.sqrt(self.varianza_b1_est),
                      't_critico_05': self.t_critico_05,
                      't_obs_b0': self.t_obs_b0,
                      't_obs_b1': self.t_obs_b1,
                      'p_valor_b1': self.p_valor_b1}


  def imprimir_resumen(self):
    print('Resumen de la regresión lineal simple:')
    print('--------------------------------------')
    for key, value in self.resumen.items():
      if key not in ['y_est', 'residuos']:
        print(f'{key}: {value}')
    print('--------------------------------------')

  def grafico_scatter_y_lineal(self):
      # Grafica los puntos de los datos originales y la recta de mejor ajuste por mínimos cuadrados obtenida por regresión lineal simple.
      if 'y_est' in self.resumen:
        self.y_estimada = self.resumen['y_est']
      else:
        self.calcular_regresion()
        self.y_estimada = self.resumen['y_est']

      plt.figure(figsize=(10, 6))
      plt.scatter(self.datos_x, self.datos_y, label="Datos")
      plt.plot(self.datos_x, self.y_estimada, label="Recta Estimada", linestyle="--", color="green")
      plt.xlabel(self.datos_x_label)
      plt.ylabel(self.datos_y_label)
      plt.title("Gráfico de Dispersión con Recta de Mejor Ajuste")
      plt.legend()
      plt.show()

  def calcular_t_obs_b1_otro(self, b1_propuesto = 0):
    # Calcula t_obs_b1_otro para b1 bajo H0: b1 = b1_propuesto, por DEFECTO = 0.
    self.t_obs_b1_otro = (self.b1_est-b1_propuesto)/np.sqrt(self.varianza_b1_est)
    return self.t_obs_b1_otro

  def calcular_t_obs_b0_otro(self,b0_propuesto = 0):
    # Calcula t_obs_b0_otro para b0 bajo H1: b0 = b0_propuesto, por DEFECTO = 0.
    self.t_obs_b0_otro = (self.b0_est-b0_propuesto)/np.sqrt(self.varianza_b0_est)
    return self.t_obs_b0_otro

  def calcular_t_critico(self,alfa=0.05):
    # Calcula el t_critico (teórico = tabulado) para dar el intervalo BILATERAL (alfa/2 para cada lado). Por DEFECTO = 0.05.
    self.t_critico = t.ppf(1-(alfa/2),len(self.datos_x)-2)
    print(f'Región RECHAZO: (-∞,- {self.t_critico:.4f}) ∪ ({self.t_critico:.4f},∞)')
    return self.t_critico

  def calcular_intervalo_confianza(self,x_0, alfa=0.05, pred=False):
    # Calcula intervalo de confianza para mu_y|x=x_0, dado un valor puntual de x
    # Si pred=True, calcula intervalo de predicción puntual para y|x=x0.
    # Necesito coviaranza de (b0_est, b1_est).
    t_critico = t.ppf(1-(alfa/2),len(self.datos_x)-2)
    cov_01=-np.mean(self.datos_x)*self.sigma2_est/sum((self.datos_x-np.mean(x))**2)
    SE2_conf_est=self.varianza_b0_est+(x_0**2)*self.varianza_b1_est+2*x_0*cov_01
    y0=self.b0_est+self.b1_est*x_0

    intervalo = [y0-t_critico*np.sqrt(SE2_conf_est),y0+t_critico*np.sqrt(SE2_conf_est)]

    print(f'Valor predicho para y|x={x_0}: {y0}')

    if pred:
      SE2_pred_est=SE2_conf_est + self.sigma2_est
      intervalo = [y0-t_critico*np.sqrt(SE2_pred_est),y0+t_critico*np.sqrt(SE2_pred_est)]
      print(f'Intervalo de predicción para y|x={x_0}: [{intervalo[0], {intervalo[1]}}')
    else:
        print(f'Intervalo de confianza para mu_y|x={x_0}: [{intervalo[0], {intervalo[1]}}')

    return intervalo


## Usando el paquete sm
  # Métodos:
    # -calcular_regresion_sm
    # -calcular_varianza_error_sm : mse_resid (SCE/gl)
    # -calcular_r2_sm
    # -calcular_se_betas_sm
    # -calcular_p_valores_sm
    # -calcular_int_conf_betas_sm
    # -calcular_t_obs_b0_sm
    # -calcular_t_obs_b1_sm
    # -calcular_int_conf_pred_nuevo_x_sm

  def calcular_regresion_sm(self):
    self.X = sm.add_constant(self.datos_x)
    self.modelo = sm.OLS(self.datos_y, self.X)
    self.resultado = self.modelo.fit()
    print(self.resultado.summary())

    # Calcula b0,b1
    self.betas_sm = self.resultado.params
    print("Parámetros de la regresión:")
    print("b0:", self.betas_sm.values[0])
    print("b1:", self.betas_sm.values[1])

    # Calcula la varianza del error
    self.varianza_error_sm = self.resultado.mse_resid
    print("Varianza del error:", self.varianza_error_sm)

    # Calcula el coeficiente de determinación
    self.r2_sm = self.resultado.rsquared
    print("Coeficiente de determinación:", self.r2_sm)

    # Calcula los desvíos standard para b0 y b1
    self.se_betas_sm = self.resultado.bse
    print("Errores estándar de los coeficientes:")
    print("SE(b0.est):", self.se_betas_sm.values[0])
    print("SE(b1.est):", self.se_betas_sm.values[1])

    # Calcula el p_valor para H0: bi = 0.
    self.p_valores_sm = self.resultado.pvalues
    print("P-valores de los coeficientes:")
    print("P-valor(b0.est):", self.p_valores_sm.values[0])
    print("P-valor(b1.est):", self.p_valores_sm.values[1])

  def calcular_t_obs_b0_sm(self, b0_propuesto = 0):
    # Calcula t_obs para b0 bajo H0: b0 = b0_propuesto, por DEFECTO = 0.
    self.t_obs_b0_sm = (self.betas_sm.values[0]-b0_propuesto)/self.se_betas_sm.values[0]
    print("t_obs(b0.est):", self.t_obs_b0_sm)
    #return self.t_obs_b0_sm

  def calcular_t_obs_b1_sm(self, b1_propuesto = 0):
    # Calcula t_obs para b1 bajo H0: b1 = b1_propuesto, por DEFECTO = 0.
    self.t_obs_b1_sm = (self.betas_sm.values[1]-b1_propuesto)/self.se_betas_sm.values[1]
    print("t_obs(b1.est):", self.t_obs_b1_sm)
    #return self.t_obs_b1_sm

  def calcular_int_conf_betas_sm(self, alfa=0.05):
    # Calcula el intervalo de confianza para b0 y b1
    self.int_conf_betas_sm = self.resultado.conf_int(alpha=alfa)
    print("Intervalo de confianza para b0.est:", self.int_conf_betas_sm.values[0])
    print("Intervalo de confianza para b1.est:", self.int_conf_betas_sm.values[1])

  def calcular_int_conf_pred_nuevo_x_sm(self, x_new, alfa=0.05, int_pred=False):
    # Nuevo punto de predicción
    self.x_new = x_new

    # Respuesta estimada para x_new
    self.y_new = self.betas_sm.values[0] + self.betas_sm.values[1] * self.x_new
    print("Respuesta estimada para x_new:", self.y_new)

    # Crear la matriz de diseño con el nuevo punto de predicción
    X_new = sm.add_constant(np.array([[1, self.x_new]]))

    # Obtener el intervalo de predicción para el nuevo punto
    prediccion = self.resultado.get_prediction(X_new)
    self.int_conf = prediccion.conf_int(alpha =alfa)
    print("Intervalo de confianza para la respuesta MEDIA a UN valor nuevo:", self.int_conf)
    if int_pred:
      self.int_pred = prediccion.conf_int(obs=True, alpha=alfa)
      print("Intervalo de predicción para la respuesta a UN valor nuevo:", self.int_pred)

import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

class RegresionLineal:
    ''' Implementa Regresion Lineal Simple y Múltiple como clases hijas de Regresion Linal.

    '''
    def __init__(self, y, x):
      # x = variables predictora/s
      # y = variable respuesta
      if len(x) != len(y):
          print('Los datos no tienen la misma longitud.')
          return

      self.x = np.asarray(x, dtype=float)
      self.y = np.asarray(y, dtype=float)
      self.resumen_ajuste_sm = None

    def mostrar_estadisticas(self):
      # Muestra estadísticas de y solamente
      n = len(self.y)
      media_y = sum(self.y)/n
      varianza_y = sum((self.y-media_y)**2/(n-1))
      min_y = min(self.y)
      max_y = max(self.y)
      print(f'Cantidad de datos: {n}.')
      print(f'Media de y       : {media_y}.')
      print(f'Varianza muestral de y    : {varianza_y}.')
      print(f'Desvío std muestral de y  : {varianza_y**0.5}')
      print(f'Rango de y       : [{min_y},{max_y}]')

    def ajustar_modelo_sm(self):
      # Estimo modelo de regresión lineal
      # Genero result, ajustados y resumen (diccionario)
      self.X = sm.add_constant(self.x,prepend=True)      #Aseguro que b0 sea el primero en params
      self.modelo_sm = sm.OLS(self.y, self.X)
      self.result_sm = self.modelo_sm.fit()
      self.ajustados = np.dot(self.X, self.result_sm.params)
      # podría usar result_sm.fittedvalues, es lo mismo

      self.resumen_ajuste_sm ={'betas': self.result_sm.params,
                            'p_valores': self.result_sm.pvalues,
                            'predichos': self.ajustados,
                            'r2_ajustado': self.result_sm.rsquared_adj,
                            'resultado': self.result_sm,
                            'summary': self.result_sm.summary()}

    def mostrar_ajuste_sm(self):
      print(self.resumen_ajuste_sm['summary'])

class RegresionLinealSimple(RegresionLineal):
    def __init__(self, y, x):
      super().__init__(y, x)
      if self.x.ndim != 1:
        print('x debe ser un vector.')
        return

   def predecir(self, new_x):
    #new_x es un valor puntual
      new_X = np.array([1,new_x])
      self.y_nuevo = np.dot(new_X, self.result_sm.params)
      print("Respuesta estimada para x_new:", self.y_nuevo)
      return self.y_nuevo

    def predecir_sm(self, new_x, alfa = 0.05):
      new_X = np.array([1,new_x])
      self.prediccion_sm = self.result_sm.get_prediction(new_X, alpha=alfa)
      self.y_nuevo_sm = self.prediccion_sm.predicted_mean[0]
      self.intervalo_confianza_y_nuevo_sm = self.prediccion_sm.conf_int(alpha=alfa)[0]
      self.intervalo_prediccion_y_nuevo_sm = self.prediccion_sm.conf_int(obs=True,alpha=alfa)[0]

      self.resumen_prediccion_sm = {'x_nuevo':new_x,
                            'y_estimado':self.y_nuevo_sm,
                            'int. conf. y_estimado':self.intervalo_confianza_y_nuevo_sm,
                            'int. pred. y_estimado':self.intervalo_prediccion_y_nuevo_sm}
      return self.resumen_prediccion_sm

    def mostrar_prediccion_sm(self):
      print(self.resumen_prediccion_sm)

    def graficar_recta_ajustada(self, label_x='x', label_y='y'):
    # Grafica los puntos de los datos originales y la recta de mejor ajuste por mínimos cuadrados obtenida por regresión lineal simple.
    if self.resumen_ajuste_sm is None:
      print('Debe ajustar el modelo antes de graficar.')
      return

    y_estimada = self.resumen_ajuste_sm['predichos']

    plt.figure(figsize=(10, 6))
    plt.scatter(self.x, self.y, label="Datos")
    plt.plot(self.x, self.y_estimada, label="Recta Estimada", linestyle="--", color="green")
    plt.xlabel('Predictora x')
    plt.ylabel('Respuesta y')
    plt.title("Gráfico de Dispersión con Recta de Mejor Ajuste")
    plt.legend()
    plt.show()

class RegresionLinealMultiple(RegresionLineal):
    def __init__(self, y, x):
      super().__init__(y, x)
      if self.x.ndim != 2:
        print('x debe ser una matriz.')
        return

    def predecir_sm(self, new_x, alfa=0.05):

      #new_x debe ser np.array([1,valores])

      self.prediccion_sm = self.result_sm.get_prediction(new_x)

      self.y_nuevo_sm = self.prediccion_sm.predicted_mean

      self.intervalo_confianza_y_nuevo_sm = self.prediccion_sm.conf_int(alpha=alfa)

      self.intervalo_prediccion_y_nuevo_sm = self.prediccion_sm.conf_int(obs=True,alpha=alfa)

      return self.y_nuevo_sm, self.intervalo_confianza_y_nuevo_sm, self.intervalo_prediccion_y_nuevo_sm

    def predecir_sm(self, new_x, alfa= 0.05):

      if new_x.ndim == 1:
          new_x = new_x.reshape(1, -1)

      new_X = sm.add_constant(new_x, prepend=True)


      prediccion = self.result_sm.get_prediction(new_X, alpha=alfa)

      self.y_nuevo_sm = prediccion.predicted_mean
      self.intervalo_confianza_y_nuevo_sm = prediccion.conf_int(alpha=alfa)
      self.intervalo_prediccion_y_nuevo_sm = prediccion.conf_int(obs=True, alpha=alfa)

      self.resumen_prediccion_sm = {
          'y_estimado': self.y_nuevo_sm,
          'int. conf. y_estimado': self.intervalo_confianza_y_nuevo_sm,
          'int. pred. y_estimado': self.intervalo_prediccion_y_nuevo_sm
      }

      return self.resumen_prediccion_sm

    def mostrar_prediccion_sm(self):
      """Muestra el diccionario de resultados de la última predicción de statsmodels."""
      if self.resumen_prediccion_sm is None:
          print("No se ha realizado ninguna predicción con statsmodels.")
          return
      print("--- Resultados de Predicción ---")
      df_pred = pd.DataFrame({
          'Y Predicho': self.resumen_prediccion_sm['y_estimado'],
          'IC Inferior': self.resumen_prediccion_sm['int. conf. y_estimado'][:, 0],
          'IC Superior': self.resumen_prediccion_sm['int. conf. y_estimado'][:, 1],
          'IP Inferior': self.resumen_prediccion_sm['int. pred. y_estimado'][:, 0],
          'IP Superior': self.resumen_prediccion_sm['int. pred. y_estimado'][:, 1]
      })
      print(df_pred.to_string())

import random
# Funciona OK. 02-06-25
class Separacion_train_test():
    ''' Separa datos en datos_train y datos_test
      Argumento: datos como dataframe.

      Método:
          particion(p_train,seed)
                p_train: [0,1] proporción de datos para train: ej: 0.8
                seed: valor de la semilla para la elección random: defecto=10
      Ejemplo de uso:
          datos_train,datos_test = Separacion_train_test(datos).particion(0.8,10)
    '''

    def __init__(self,datos):
      if len(datos) == 0:
        print('No hay datos.')
        return
      self.datos = datos


    def particion(self,p_train,seed=10):
      if p_train < 0 or p_train > 1:
        print('p_train debe estar entre 0 y 1.')
        return
      n = self.datos.shape[0]
      n_train = int(n*p_train)
      n_test = n - n_train

      random.seed(seed)
      cuales = self.datos.index[random.sample(range(n), n_train)]
      datos_test = self.datos.drop(cuales)
      datos_train = self.datos.iloc[cuales]
      return datos_train, datos_test

# Funciona OK. 11-06-25. Achiqué código en tabla de confusión.
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.metrics import auc
import pandas as pd
import random

#16-06-25 16:25
class RegresionLogistica():
  ''' Clase para regresión logística.

    Métodos:
      calcular_logit(datos_y, datos_x)
      entrenar_logit(datos_y_train, datos_x_train)
      testear_logit(datos_y_test, datos_x_test)
      evaluar_modelo(umbral)
      imprimir_evaluacion_modelo()
      graficar_roc(p_min=0,p_max=1,num_puntos=100)

    # Ejemplo de uso.
      # 0. Separo datos con la clase Separacion_train_test
      datos_train,datos_test = Separacion_train_test(datos).particion(0.8,10)

      #1. Entreno modelo
      modelo = RegresionLogistica()
      resultado_train = modelo.entrenar_logit(y_train, x_train)

      #2. Testeo modelo
      resultado_testeo = modelo.testear_logit(y_test, x_test)

      #3. Tabla de confusión, sensibilidad y especificidad
      evaluacion = modelo.evaluar_modelo(0.5)
      modelo.imprimir_evaluacion_modelo()

      #4. Roc y auc
      modelo.graficar_roc()
  '''

  def __init__(self):
      self.resultado = None


  def calcular_logit(self, datos_y, datos_x):
    # Calcula los atributos esenciales del modelo de regresión logística.
    self.datos_y = datos_y
    self.datos_x = datos_x

    self.X = sm.add_constant(self.datos_x)
    modelo = sm.Logit(self.datos_y, self.X)
    self.resultado = modelo.fit()
    self.summary = self.resultado.summary()
    print(self.summary)

    # Calcula betas
    self.betas = self.resultado.params

    # Calcula el pseudo coeficiente de determinación
    self.pseudor2 = self.resultado.prsquared

    # Calcula el p_valor para H0: bi = 0.
    self.p_valores_betas = self.resultado.pvalues

    # Calcula los y_estimados por el modelo
    self.y_estimados = self.resultado.fittedvalues

    self.resumen_regresion = {
              'resultado':self.resultado,
              'betas':self.betas,
              'pseudor2':self.pseudor2,
              'p_valores_betas':self.p_valores_betas,
              'y_estimados':self.y_estimados,
              'summary':self.summary}
    return self.resumen_regresion


  def entrenar_logit(self,datos_y_train, datos_x_train):
    # Genero el modelo entrenado
    self.resultado_train = self.calcular_logit(datos_y_train, datos_x_train)
    return self.resultado_train


  def testear_logit(self,datos_y_test, datos_x_test):
    # Genero el testeo del modelo entrenado
    if self.resultado_train is None:
      print('No se ha entrenado el modelo.')
      return
    else:
      self.datos_y_test = datos_y_test
      self.datos_x_test = datos_x_test
      X_test = sm.add_constant(self.datos_x_test)
      self.resultado_test = self.calcular_logit(self.datos_y_test, self.datos_x_test)
      self.predicciones = self.resultado_train['resultado'].predict(X_test)
      return self.resultado_test


  def evaluar_modelo(self, umbral):
    '''
    Evalua el modelo entrenado.
    Dado umbral, crea matriz de confusión, calcula error de clasificación, sensibilidad y especificidad.
    '''
    if umbral is None:
      print('No se ha especificado un umbral.')
      return
    elif umbral < 0 or umbral > 1:
      print('El umbral debe estar entre 0 y 1.')
      return

    if self.predicciones is None:
      print('No se ha testeado el modelo.')
      return
    else:
      y_pred = (self.predicciones >= umbral).astype(int) # vector binario: 1 si es >= a umbral

      #Matriz de confusión para umbral
      a = sum((y_pred == 1) & (self.datos_y_test == 1))
      b = sum((y_pred == 1) & (self.datos_y_test == 0))
      c = sum((y_pred == 0) & (self.datos_y_test == 1))
      d = sum((y_pred == 0) & (self.datos_y_test == 0))
      tabla =  pd.DataFrame({
          'y_test=1': [a, c],
          'y_test=0': [b, d],

      }, index=['y_pred=1', 'y_pred=0'])

      # Error de clasificación
      mal_clasificados = b + c
      total = len(y_pred)
      error = mal_clasificados/total

      # Sensibilidad y especificidad
      sensibilidad = a / (a+c)
      especificidad = d / (b+d)

      self.evaluacion_modelo = {
          'tabla':tabla,
          'error':error,
          'sensibilidad':sensibilidad,
          'especificidad':especificidad
      }
      return self.evaluacion_modelo


  def imprimir_evaluacion_modelo(self):
    # Imprime resultados de la evaluación: tabla confusión, error, sens y espec

    if self.evaluacion_modelo is None:
      print('No se ha evaluado el modelo.')
      return
    else:
      print('Matriz de confusión:')
      print(self.evaluacion_modelo['tabla'])
      print('Error de clasificación:', self.evaluacion_modelo['error'])
      print('Sensibilidad (VP/TotPReal:positivos correctos detectados/total que debería haber detectado (y_test=1):', self.evaluacion_modelo['sensibilidad'])
      print('Especificidad (VN/TotNReal:negativos correctos detectados/total de negativos que debería haber detectado (y_test=0):', self.evaluacion_modelo['especificidad'])


  def graficar_roc(self,p_min=0,p_max=1,num_puntos=100):
    # Grafica ROC, calcula p de corte óptimo, sensibilidad y especificidad.

    if self.predicciones is None:
      print('No se ha testeado el modelo.')
      return

    # Generar valores de p
    p_values = np.linspace(p_min, p_max, num_puntos)

    # Listas para almacenar sensibilidad y especificidad
    sensibilidad = []                              # TPR
    especificidad = []                             # TNR
    for p in p_values:
        # Calcular matriz de confusión
        confusion_p = self.evaluar_modelo(p)['tabla']
        a = confusion_p.loc['y_pred=1','y_test=1']    # TP
        b = confusion_p.loc['y_pred=1','y_test=0']    # FP
        c = confusion_p.loc['y_pred=0','y_test=1']    # FN
        d = confusion_p.loc['y_pred=0','y_test=0']    # TN
        # Calcular sensibilidad y especificidad
        sensibilidad.append(a/(a+c))
        especificidad.append(d/(b+d))

    # Punto de corte, sensibilidad y especificidad
    idx_umbral_p = np.argmax(np.array(sensibilidad)+np.array(especificidad)-1)
    umbral_p = p_values[idx_umbral_p]
    sensibilidad_p = sensibilidad[idx_umbral_p]
    especificidad_p = especificidad[idx_umbral_p]

    # AUC: FPR, TPR
    roc_auc = auc(1-np.array(especificidad), sensibilidad)

    # Graficar ROC
    plt.plot(1-np.array(especificidad), sensibilidad)
    plt.xlabel('1-especificidad (FPR)')
    plt.ylabel('sensibilidad (TPR)')
    plt.title('Curva ROC')
    plt.grid(True)
    plt.show()
    print('Umbral p (índice de Youden):', umbral_p)
    print('Sensibilidad (TPR):', sensibilidad_p)
    print('Especificidad (TNR):', especificidad_p)
    print("AUC:", roc_auc)

# Funciona OK. 11-06-2025 10:40
from scipy.stats import chi2

class mi_test_chi2:
  ''' Evalúa bondad de ajuste de distribución, pensado para variables categóricas (cualitativas): solamente quiero saber si los valores observados se aproximan a los esperados según la distribución propuesta.

    Implementa test chi2 para bondad de ajuste de distribución.
        - H0: distribución = modelo
        - H1: distribución \neq modelo

    - Recibe:
        - 2 arrays (valores observados y valores estimados por modelo), y nivel alfa para región de rechazo.
        - k = número de parámetros del modelo que fueron calculados con la muestra (Ej: Media o varianza => k=1.  Ambas: k=2).
        - alfa es 0.05 por defecto
    - Métodos:
        - _calculo_chi2_: el parámetro de bondad (chi2)
        - testeo_chi2: creo {resultado} del test
        - imprimir_informe: imprime el informe del test
    - Retorna:
        - valores: p-valor, chi2 observado, valor chi2 teórico, grados de libertad, conclusión

    - Ejemplo de uso:
        test2 = mi_test_chi2(valores_obervados, valores_esperados, k=0, alfa=0.01)
        test2.testeo_chi2()
        test2.imprimir_informe()
  '''

  def __init__(self, Obs, Est, k = 0, alfa = 0.05):
    # Chequeo que los vectorres tengan longitudes positivas e iguales, y que Est no tenga valores <= 0 para poder dividir.
    if len(Obs) != len(Est) or (len(Obs)==0) or (len(Est)==0) or np.any(np.array(Est)<=0):
      print("Datos incorrectos.")
      return
    self.obs = Obs
    self.est = Est
    self.N = len(Obs)
    self.k = k
    self.alfa = alfa
    self.resultado = None

  def _calculo_chi2_(self):
    # Calcula el parámetro chi2 a partir de los datos observados y los estimados por modelo.

    O = self.obs
    E = self.est
    chi2_obs = sum(((O - E)**2)/E)
    return chi2_obs

  def testeo_chi2(self):
    # LLama _calculo_chi2_ para el estadístico observado, obtiene el teórico para el alfa y los gl dados. Emite resultado (diccionario).
    N = self.N
    k = self.k
    alfa = self.alfa                     # alfa: significancia
    gl = N - 1 - k                       # grados de libertad
    chi2_obs = self._calculo_chi2_()     # estadístico observado
    chi2_teor = chi2.ppf(1 - alfa,gl)    # estadístico teórico
    p_valor = 1 - chi2.cdf(chi2_obs,gl)  # p-valor
    if p_valor <= alfa:                  # conclusión
      informe = 'Hay evidencia para rechazar H0: el modelo NO es adecuado.'
    else:
      informe = 'No hay evidencia para rechazar H0: el modelo ES adecuado.'
    self.resultado = {'p-valor': p_valor,
                  'chi2_obs': chi2_obs,
                  'chi2_teorico': chi2_teor,
                  'alfa': alfa,
                  'gl': gl,
                  'informe': informe}


  def imprimir_informe(self):
    if self.resultado == None:
      print('No se evaluaron los datos.')
      return
    else:
      resultado = self.resultado
    print("INFORME TEST DE BONDAD DE AJUSTE (Chi2)")
    print("=======================================")
    print("H0: el modelo propuesto ajusta los datos adecuadamente")
    print("H1: el modelo propuesto NO ajusta los datos adecuadamente")
    print("---------------------------------------------------------")
    print(f"Nivel de significancia (alfa):{resultado['alfa']}                Grados de libertad: {resultado['gl']}")
    print(f"Estadístico chi2 observado: {resultado['chi2_obs']:.5f}                Estadístico chi2 teórico: {resultado['chi2_teorico']:.5f}")
    print(f"                                  p-valor: {resultado['p-valor']:.5f}")
    print("=======================================")
    print("Conclusión del test")
    print("-------------------")
    print(resultado['informe'])

import numpy as np
import pandas as pd
from scipy.stats import t

# FUNCIONA OK. 11-06-25
def comparar_medias_t(resultado_mi_anova, grupo_A_label, grupo_B_label, alfa=0.05):
    """
    Realiza un t-test de muestras independientes para comparar las medias
    de dos grupos específicos de un factor, asumiendo varianzas iguales.
    Solo debería realizarse si el ANOVA general fue significativo.

    - Requiere que se haya instanciado mi_anova_lm con (y,x).
    """
    datos_y = resultado_mi_anova.y
    datos_x = resultado_mi_anova.x

    y_A = datos_y[datos_x == grupo_A_label]
    y_B = datos_y[datos_x == grupo_B_label]

    if len(y_A) == 0 or len(y_B) == 0:
        print('Datos incorrectos.')
        return

    n_A = len(y_A)
    n_B = len(y_B)
    media_A = np.mean(y_A)
    media_B = np.mean(y_B)
    diferencia_medias = media_A - media_B

    gl_M = resultado_mi_anova.gl_M
    Sp2 = resultado_mi_anova.varianza_general_agrupada  # es la MSE = RSS_M / gl_M
    SE_diferencia = np.sqrt(Sp2*(1/n_A+1/n_B))   # error std de la diferencia
    t_critico = t.ppf(1 - alfa/2,gl_M)
    margen_error = t_critico * SE_diferencia
    lim_inf = diferencia_medias - margen_error
    lim_sup = diferencia_medias + margen_error
    gl_t = n_A+n_B-2
    t_observado = diferencia_medias / SE_diferencia
    p_valor_t = 2*t.cdf(-abs(t_observado), df=gl_t)
    print('El intervalo de confianza es:',lim_inf,lim_sup)


    # Informe
    print(f'La estimación de la diferencia de la diferencia de medias entre los grupos {grupo_A_label} y {grupo_B_label} través de un intervalo del {100*(1-alfa)}% de confianza es:',lim_inf,lim_sup)
    if np.sign(lim_inf) != np.sign(lim_sup):
      print(f'Como el intervalo incluye el cero, no hay evidencia significativa de que el agrupamiento difiera al nivel del {100*alfa}%. Esto coincide con el resultado no significativo del ANOVA (p_valor = {resultado_mi_anova.p_valor} >{alfa}).')
    else:
      print(f'Como el intervalo NO incluye el cero, hay evidencia significativa de que el los grupos difieren al nivel del {100*alfa}%. Esto coincide con el resultado significativo del ANOVA (p_valor = {resultado_mi_anova.p_valor} <={alfa}).')

    print(f"-- Comparación de Medias: '{grupo_A_label}' vs '{grupo_B_label}' ---")
    print(f"Media '{grupo_A_label}': {media_A:.4f} (n={n_A})")
    print(f"Media '{grupo_B_label}': {media_B:.4f} (n={n_B})")
    print(f"Diferencia de Medias: {diferencia_medias:.4f}")
    print(f"t_observado: {t_observado:.4f}")
    print(f"t_critico: {t_critico:.4f}")
    print(f"Grados de libertad: {gl_t}")
    print(f"P-valor: {p_valor_t:.4f}")



    if p_valor_t<= alfa:
        print(f"**CONCLUSIÓN:** Con α={alfa}, hay evidencia para **RECHAZAR H0**. "
              f"La diferencia entre las medias de '{grupo_A_label}' y '{grupo_B_label}' es estadísticamente significativa.")
    else:
        print(f"**CONCLUSIÓN:** Con α={alfa}, no hay suficiente evidencia para **RECHAZAR H0**. "
              f"La diferencia entre las medias de '{grupo_A_label}' y '{grupo_B_label}' NO es estadísticamente significativa.")

import seaborn as sns
import matplotlib.pyplot as plt
# 16-06-25
def grafico_factor(data):
  ''' Grafica boxplot de la respuesta vs niveles del factor.
    PREVIO A ANOVA.
    - Recibe: DATAFRAME 2 columnas (respuesta y,predictora x)
    - Devuelve: gráfico boxplot.
    - Ejemplo de uso:
      datos= pd.read_csv(camino+'dengue.csv', sep=';')
      dengue = pd.DataFrame(datos)
      grafico_factor(dengue)
  '''
  plt.figure(figsize=(8, 6))
  respuesta_label = data.columns[0]
  predictora_label = data.columns[1]
  sns.boxplot(data=data, x=predictora_label, y=respuesta_label);
  plt.ylabel(respuesta_label)
  plt.title(f'Distribución de {respuesta_label} por {predictora_label}')
  plt.show()

import statsmodels.api as sm
import numpy as np
from statsmodels.stats.anova import anova_lm
from scipy.stats import f,t,norm,shapiro
import seaborn as sns
from statsmodels.stats.diagnostic import het_breuschpagan, het_white
import matplotlib.pyplot as plt
import pandas as pd

#16-06-25 16:25
class mi_anova_lm:
  ''' Clase para realizar ANOVA de un factor: incidencia de factores de una variable predictora en la variabilidad de una variable dependiente.

  - Modelo lineal de anova: Y_ij = mu_i + e_ij, e_ij \sim N(0,s2), i niveles, j individuos en cada nivel.
    - Hipótesis:
      H0: mu_i = mu_j (las medias son iguales)
      H1: alguna es diferente
  - Al convertirlo en regresión múltiple con dummies en los niveles:
      Modelo: Y_i = b_0 + b_1 x_i1 + b_2 x_i2 +.. + e_i, e_i \sim N(0,s2), i individuos, b_i = coeficientes de cada nivel, x_i = 1 si pertenece al nivel i, 0 si no.
      Hipótesis:
      H0: b_0 = b_0+b_1 = ... = b_0+b_n = 0
        equivale H0: b_i = 0, i=1,...,n
      H1: alguna es diferente
    - Bajo H0: modelo: Y_i = b_0 + e_i, e_i \sim N(0,s2)
    - Bajo H1: modelo: Y_i = b_0 + b_i + e_i, e_i \sim N(0,s2), i=1,n

  - Implementa test F para igualdad de medias de los niveles del factor.
  - Recibe: 2 DATAFRAME: y (respuesta) y x (predictora, con niveles).


  La idea es que un modelo suponga que el factor influye: va a tener todos los niveles del factor como variables; el otro modelo, nulo o reducido, va a suponer que el factor no influye, por lo que los datos solo tienen variabilidad natural y todos los bi=0, salvo b0 que es la media global.

  - Supuestos:
    -datos independientes (sin relación entre sí, se controla en el diseño del experimento,
    -errores normalmente distribuidos (Shapiro si n<50, else qq) y
    -homocedasticidad en el modelo de regresión (errores tienen varianza constante, con Breusch-Pagan; es mejor usar Barlett para grupos categóricos).

  - Compara:
    - modelo_M con todos los niveles del factor pasados a dummies
    - modelo_m solo con 1's (esto es b0, estimador de la media general, para todos los datos)

    - Recibe: 2 DATAFRAME: y (respuesta) y x (predictora, con niveles).
    - Métodos:
      - _ajustar_modelos():
          Hace dummies de x y crea el modelo de regresión múltiple (OLS) completo (modelo_M) y el modelo nulo (modelo_m).
      - _creo_tabla_anova(): usa modelo_m y modelo_M para crear la tabla de anova con anova_lm().
      - informe_anova(): usa tabla_anova para crear el informe.

      - OBS:
        -si n grande, no se hace análisis de residuos xq t-> N
        -dummies: irrelevante cual es referencia.

      - Ejemplo de uso:
        datos= pd.read_csv(camino+'dengue.csv', sep=';')
        dengue = pd.DataFrame(datos)
        y = dengue['plaquetas']
        x = dengue['tipo_dengue']
        anova = mi_anova_lm(y,x)
        anova.informe_anova(0.05)
  '''
  def __init__(self, y,x):
    self.y = np.asarray(y)
    self.x = np.asarray(x)
    if len(y) != len(x):
      print("Datos incorrectos.")
      return
    self.modelo_M = None
    self.modelo_m = None
    self.resultado_M = None
    self.resultado_m = None
    self.gl_m = None
    self.gl_M = None
    self.F_critico = None
    self.p_valor = None
    self.F_obs = None
    self.varianza_general_agrupada = None
    self.varianza_sin_agrupacion = None
    self.informe = None
    self.tabla_anova = None

  def _ajustar_modelos(self):
    x_d=pd.get_dummies(self.x,drop_first=True).astype(int)

    #Hago regresión lineal con las predictoras: modelo_M
    X_d = sm.add_constant(x_d)
    self.modelo_M = sm.OLS(self.y, X_d)
    self.resultado_M= self.modelo_M.fit()

    # Hago regresión para el modelo sin el factor: modelo_m
    n=len(self.y)
    X_1 =  np.ones((n, 1))
    self.modelo_m= sm.OLS(self.y, X_1)
    self.resultado_m= self.modelo_m.fit()

  def _creo_tabla_anova(self):
    if self.resultado_m is None or self.resultado_M is None:
      self._ajustar_modelos()

    self.tabla_anova = anova_lm(self.resultado_m,self.resultado_M)
    return self.tabla_anova

  def informe_anova(self, alfa=0.05):
    if self.resultado_m is None or self.resultado_M is None:
      self._ajustar_modelos()
      self.tabla_anova = self._creo_tabla_anova()

    print(self.tabla_anova)
    RSS_M = self.tabla_anova.ssr[1]
    self.gl_M = self.tabla_anova.df_resid[1]
    RSS_m = self.tabla_anova.ssr[0]
    self.gl_m = self.tabla_anova.df_resid[0]

    self.varianza_general_agrupada = RSS_M /self.gl_M             # es la Sp2
    self.varianza_sin_agrupacion = RSS_m / self.gl_m
    print('Estimación de la varianza general por efecto de la agrupación, suponiendo que los grupos tienen varianzas iguales (Sp2):',self.varianza_general_agrupada)
    print('El modelo_m tiene toda la variabilidad (no hay explicación por los grupos).')
    print('El modelo_M tiene menos variabilidad (hay explicación debida a la agrupación (menos gl)).')
    print('Varianza general sin grupos:', self.varianza_sin_agrupacion)
    self.F_obs = self.tabla_anova.F[1]
    print('El estadístico F_obs es:',self.F_obs)
    self.p_valor = self.tabla_anova['Pr(>F)'][1]
    print('El p-valor es:',self.p_valor)

    self.F_critico = f.ppf(1-alfa,self.gl_M,self.gl_m)
    print(f'El F_critico con αlfa={alfa}, es {self.F_critico}')

    print('--------------')
    print('COMCLUSION ANOVA')
    print('(asumiendo que se verifican todos los supuestos: independencia, normalidad de errores y varianzas constantes de errores.)')
    print('--------------')
    if self.p_valor <= alfa:
        self.informe = (f'Dado que el p-valor ({self.p_valor:.5f}) es menor o igual a α ({alfa}), '
                        'hay evidencia para RECHAZAR la hipótesis nula (H0). '
                        'Esto sugiere que el factor tiene un efecto significativo sobre la variable dependiente.')
    else:
        self.informe = (f'Dado que el p-valor ({self.p_valor:.5f}) es mayor que α ({alfa}), '
                        'NO hay suficiente evidencia para rechazar la hipótesis nula (H0). '
                        'Esto sugiere que el factor NO tiene un efecto significativo sobre la variable dependiente.')
    print(self.informe)

  def miqqplot(data):
    #Crea qqplot manualmente.

    media = np.mean(data)
    desviacion_estandar = np.std(data)

    data_s = (data- media) / desviacion_estandar
    cuantiles_muestrales=np.sort(data_s)
    n=len(data)
    pp=np.arange(1, (n+1))/(n+1)
    cuantiles_teoricos = norm.ppf(pp)

    plt.scatter(cuantiles_teoricos, cuantiles_muestrales, color='blue', marker='o')
    plt.xlabel('Cuantiles teóricos')
    plt.ylabel('Cuantiles muestrales')
    plt.plot(cuantiles_teoricos,cuantiles_teoricos , linestyle='-', color='red')
    plt.show()

  def estudio_supuestos(self):
    ''' Estudia los supuestos de homocedasticidad y normalidad de los errores.
      - Ejecuta:
        - gráfico scatter residuos vs. predichos (homo)
        - het_breuschpagan (homo)
        - miqqplot (norm)
        - shapiro (norm)
    '''
    if self.resultado_m is None or self.resultado_M is None:
      self._ajustar_modelos()
    predichos = self.resultado_M.fittedvalues
    residuos = self.resultado_M.resid
    X = sm.add_constant(self.x)

    ## Gráfico de los residuos vs los valores predichos
    # Homocedasticidad: H0: s_i = s_j, i,j niveles.

    plt.scatter(predichos, residuos)
    plt.axhline(y=0, color='r', linestyle='--')  # Línea horizontal en y=0 para facilitar la visualización de los residuos

    plt.xlabel('Valores predichos')
    plt.ylabel('Residuos')
    plt.title('Gráfico de Residuos vs. Valores Predichos')
    plt.ylim(-10,10)
    plt.show()

    bp_test = het_breuschpagan(residuos, X)
    bp_value = bp_test[1]
    print("Valor p Homocedasticidad:", bp_value)
    if bp_value<0.05:
      print('Hay evidencia de heterocedasticidad: rechazo H0, las varianzas no son constantes')
    else:
      print('No hay evidencia de heterocedasticidad: no puedo rechazar H0, hay homocedasticidad, las varianzas son homogéneas.')

    # Normalidad de los errores
    miqqplot(residuos)

    stat, p_valor1 = shapiro(residuos)
    print("Valor p normalidad:", p_valor1)
    if p_valor1<0.05:
      print('Hay evidencia para rechazar la normalidad de los errores.')
    else:
      print('No hay evidencia para rechazar la normalidad de los errores: acepto normalildad.')