# -*- coding: utf-8 -*-
"""Mis_Clases_Limpias.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYZ6IMuqosf5AAsDFcdl9p3ZpcZmQC8R
"""

# Funciona OK. 02-06-25
import random

class Separacion_train_test():
  ''' Separa datos en datos_train y datos_test
      Argumento: datos en array o dataframe.

      Método:
          particion(p_train,seed)
                p_train: [0,1] proporción de datos para train: ej: 0.8
                seed: valor de la semilla para la elección random: defecto=10
      Ejemplo de uso:
          datos_train,datos_test = Separacion_train_test(datos).particion(0.8,10)
  '''

  def __init__(self,datos):
    self.datos = datos


  def particion(self,p_train,seed=10):
    n = self.datos.shape[0]
    n_train = int(n*p_train)
    n_test = n - n_train

    random.seed(seed)
    cuales = random.sample(range(n), n_train)
    datos_test = datos.drop(cuales)
    datos_train = datos.iloc[cuales]
    return datos_train, datos_test

# Funciona OK. 11-06-25 09:34
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.metrics import auc
import pandas as pd
import random


class RegresionLogistica():
  ''' Clase para regresión logística.

    Métodos:
      calcular_logit(datos_y, datos_x)
      entrenar_logit(datos_y_train, datos_x_train)
      testear_logit(datos_y_test, datos_x_test)
      evaluar_modelo(umbral)
      imprimir_evaluacion_modelo()
      graficar_roc(p_min=0,p_max=1,num_puntos=100)

    # Ejemplo de uso.
      # 0. Separo datos con la clase Separacion_train_test
      datos_train,datos_test = Separacion_train_test(datos).particion(0.8,10)

      #1. Entreno modelo
      modelo = RegresionLogistica()
      resultado_train = modelo.entrenar_logit(y_train, x_train)

      #2. Testeo modelo
      resultado_testeo = modelo.testear_logit(y_test, x_test)

      #3. Tabla de confusión, sensibilidad y especificidad
      evaluacion = modelo.evaluar_modelo(0.5)
      modelo.imprimir_evaluacion_modelo()

      #4. Roc y auc
      modelo.graficar_roc()
  '''

  def __init__(self):
      self.resultado = None


  def calcular_logit(self, datos_y, datos_x):
    # Calcula los atributos esenciales del modelo de regresión logística.
    self.datos_y = datos_y
    self.datos_x = datos_x

    self.X = sm.add_constant(self.datos_x)
    modelo = sm.Logit(self.datos_y, self.X)
    self.resultado = modelo.fit()
    self.summary = self.resultado.summary()
    print(self.summary)

    # Calcula betas
    self.betas = self.resultado.params

    # Calcula el pseudo coeficiente de determinación
    self.pseudor2 = self.resultado.prsquared

    # Calcula el p_valor para H0: bi = 0.
    self.p_valores_betas = self.resultado.pvalues

    # Calcula los y_estimados por el modelo
    self.y_estimados = self.resultado.fittedvalues

    self.resumen_regresion = {
              'resultado':self.resultado,
              'betas':self.betas,
              'pseudor2':self.pseudor2,
              'p_valores_betas':self.p_valores_betas,
              'y_estimados':self.y_estimados,
              'summary':self.summary}
    return self.resumen_regresion


  def entrenar_logit(self,datos_y_train, datos_x_train):
    # Genero el modelo entrenado
    self.resultado_train = self.calcular_logit(datos_y_train, datos_x_train)
    return self.resultado_train


  def testear_logit(self,datos_y_test, datos_x_test):
    # Genero el testeo del modelo entrenado
    if self.resultado_train is None:
      print('No se ha entrenado el modelo.')
      return
    else:
      self.datos_y_test = datos_y_test
      self.datos_x_test = datos_x_test
      X_test = sm.add_constant(self.datos_x_test)
      self.predicciones = self.resultado_train['resultado'].predict(X_test)


  def evaluar_modelo(self, umbral):
    '''
    Evalua el modelo entrenado.
    Dado umbral, crea matriz de confusión, calcula error de clasificación, sensibilidad y especificidad.
    '''
    if umbral = None:
      print('No se ha especificado un umbral.')
      return
    elif umbral < 0 or umbral > 1:
      print('El umbral debe estar entre 0 y 1.')
      return

    if self.predicciones is None:
      print('No se ha testeado el modelo.')
      return
    else:
      y_pred = (self.predicciones >= umbral).astype(int) # vector binario: 1 si es mayor a umbral

      #Matriz de confusión para umbral
      a = sum((y_pred == 1) & (self.datos_y_test == 1))
      b = sum((y_pred == 0) & (self.datos_y_test == 1))
      c = sum((y_pred == 1) & (self.datos_y_test == 0))
      d = sum((y_pred == 0) & (self.datos_y_test == 0))
      tabla =  pd.DataFrame({
          'y_test=1': [a, b],
          'y_test=0': [c, d],

      }, index=['y_pred=1', 'y_pred=0'])

      # Error de clasificación
      mal_clasificados = b + c
      total = len(y_pred)
      error = mal_clasificados/total

      # Sensibilidad y especificidad
      sensibilidad = a / (a+c)
      especificidad = d / (b+d)

      self.evaluacion_modelo = {
          'tabla':tabla,
          'error':error,
          'sensibilidad':sensibilidad,
          'especificidad':especificidad
      }
      return self.evaluacion_modelo


  def imprimir_evaluacion_modelo(self):
    # Imprime resultados de la evaluación: tabla confusión, error, sens y espec

    if self.evaluacion_modelo is None:
      print('No se ha evaluado el modelo.')
      return
    else:
      print('Matriz de confusión:')
      print(self.evaluacion_modelo['tabla'])
      print('Error de clasificación:', self.evaluacion_modelo['error'])
      print('Sensibilidad (VP/TotPReal:positivos correctos detectados/total que debería haber detectado (y_test=1):', self.evaluacion_modelo['sensibilidad'])
      print('Especificidad (VN/TotNReal:negativos correctos detectados/total de negativos que debería haber detectado (y_test=0):', self.evaluacion_modelo['especificidad'])


  def graficar_roc(self,p_min=0,p_max=1,num_puntos=100):
    # Grafica ROC, calcula p de corte óptimo, sensibilidad y especificidad.

    if self.predicciones is None:
      print('No se ha testeado el modelo.')
      return
    else:
    # Generar valores de p
      p_values = np.linspace(p_min, p_max, num_puntos)

    # Listas para almacenar sensibilidad y especificidad
    sensibilidad = []
    especificidad = []
    for p in p_values:
        # Calcular matriz de confusión
        confusion_p = self.evaluar_modelo(p)['tabla']
        a = confusion_p['y_test=1']['y_pred=1']
        b = confusion_p['y_test=0']['y_pred=1']
        c = confusion_p['y_test=1']['y_pred=0']
        d = confusion_p['y_test=0']['y_pred=0']
        # Calcular sensibilidad y especificidad
        sensibilidad.append(a/(a+c))
        especificidad.append(d/(b+d))

    # Punto de corte, sensibilidad y especificidad
    idx_umbral_p = np.argmax(np.array(sensibilidad)+np.array(especificidad)-1)
    umbral_p = p_values[idx_umbral_p]
    sensibilidad_p = sensibilidad[idx_umbral_p]
    especificidad_p = especificidad[idx_umbral_p]

    # AUC
    roc_auc = auc(1-np.array(especificidad), sensibilidad)

    # Graficar ROC
    plt.plot(1-np.array(especificidad), sensibilidad)
    plt.xlabel('1-especificidad')
    plt.ylabel('sensibilidad')
    plt.title('Curva ROC')
    plt.grid(True)
    plt.show()
    print('Umbral p:', umbral_p)
    print('Sensibilidad:', sensibilidad_p)
    print('Especificidad:', especificidad_p)
    print("AUC:", roc_auc)

# Funciona OK. 11-06-2025 10:40
from scipy.stats import chi2

class mi_test_chi2:
  ''' Evalúa bondad de ajuste de distribución, pensado para variables categóricas (cualitativas): solamente quiero saber si los valores observados se aproximan a los esperados según la distribución propuesta.

    Implementa test chi2 para bondad de ajuste de distribución.
        - H0: distribución = modelo
        - H1: distribución \neq modelo

    - Recibe:
        - 2 arrays (valores observados y valores estimados por modelo), y nivel alfa para región de rechazo.
        - k = número de parámetros del modelo que fueron calculados con la muestra (Ej: Media o varianza => k=1.  Ambas: k=2).
        - alfa es 0.05 por defecto
    - Métodos:
        - _calculo_chi2_: el parámetro de bondad (chi2)
        - testeo_chi2: creo {resultado} del test
        - imprimir_informe: imprime el informe del test
    - Retorna:
        - valores: p-valor, chi2 observado, valor chi2 teórico, grados de libertad, conclusión

    - Ejemplo de uso:
        test2 = mi_test_chi2(valores_obervados, valores_esperados, k=0, alfa=0.01)
        test2.testeo_chi2()
        test2.imprimir_informe()
  '''

  def __init__(self, Obs, Est, k = 0, alfa = 0.05):
    # Chequeo que los vectorres tengan longitudes positivas e iguales, y que Est no tenga valores <= 0 para poder dividir.
    if len(Obs) != len(Est) or (len(Obs)==0) or (len(Est)==0) or np.any(np.array(Est)<=0)):
      print("Datos incorrectos.")
      return
    self.obs = Obs
    self.est = Est
    self.N = len(Obs)
    self.k = k
    self.alfa = alfa
    self.resultado = None

  def _calculo_chi2_(self):
    # Calcula el parámetro chi2 a partir de los datos observados y los estimados por modelo.

    O = self.obs
    E = self.est
    chi2_obs = sum(((O - E)**2)/E)
    return chi2_obs

  def testeo_chi2(self):
    # LLama _calculo_chi2_ para el estadístico observado, obtiene el teórico para el alfa y los gl dados. Emite resultado (diccionario).
    N = self.N
    k = self.k
    alfa = self.alfa                     # alfa: significancia
    gl = N - 1 - k                       # grados de libertad
    chi2_obs = self._calculo_chi2_()     # estadístico observado
    chi2_teor = chi2.ppf(1 - alfa,gl)    # estadístico teórico
    p_valor = 1 - chi2.cdf(chi2_obs,gl)  # p-valor
    if p_valor <= alfa:                  # conclusión
      informe = 'Hay evidencia para rechazar H0: el modelo NO es adecuado.'
    else:
      informe = 'No hay evidencia para rechazar H0: el modelo ES adecuado.'
    self.resultado = {'p-valor': p_valor,
                  'chi2_obs': chi2_obs,
                  'chi2_teorico': chi2_teor,
                  'alfa': alfa,
                  'gl': gl,
                  'informe': informe}


  def imprimir_informe(self):
    if self.resultado == None:
      print('No se evaluaron los datos.')
      return
    else:
      resultado = self.resultado
    print("INFORME TEST DE BONDAD DE AJUSTE (Chi2)")
    print("=======================================")
    print("H0: el modelo propuesto ajusta los datos adecuadamente")
    print("H1: el modelo propuesto NO ajusta los datos adecuadamente")
    print("---------------------------------------------------------")
    print(f"Nivel de significancia (alfa):{resultado['alfa']}                Grados de libertad: {resultado['gl']}")
    print(f"Estadístico chi2 observado: {resultado['chi2_obs']:.5f}                Estadístico chi2 teórico: {resultado['chi2_teorico']:.5f}")
    print(f"                                  p-valor: {resultado['p-valor']:.5f}")
    print("=======================================")
    print("Conclusión del test")
    print("-------------------")
    print(resultado['informe'])